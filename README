from tensorflow.keras.models import Sequential


scaler = MinMaxScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)


################
# For a multi-class classification problem
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# For a binary classification problem
model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# For a mean squared error regression problem
model.compile(optimizer='rmsprop',
              loss='mse')


##############

model = Sequential()

model.add(Dense(4,activation='relu'))
model.add(Dense(4,activation='relu'))
model.add(Dense(4,activation='relu'))

# Final output node for prediction
model.add(Dense(1))

model.compile(optimizer='rmsprop',loss='mse')
model.fit()
model.fit(X_train,y_train,epochs=250)
model.history.history
loss = model.history.history['loss']
plt.plot(loss)

model.evaluate(X_test, y_test, verbose = 0)

from sklearn.metrics import mean_absolute_error,mean_squared_error
mean_absolute_error(pred_df['Test Y'],pred_df['Model Predictions'])
mean_squared_error(pred_df['Test Y'],pred_df['Model Predictions'])

new_gem = [[998,1000]]
new_gem = scaler.transform(new_gem)
model.predict(new_gem)


from tensorflow.keras.models import load_model
model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'
later_model = load_model('my_model.h5')

#######


df.describe().transpose()
sns.distplot(df['price'])
sns.countplot(df['bedrooms'])

df.corr()['price'].sort_values()
sns.scatterplot(x='price',y='sqft_living',data=df)
sns.boxplot(x='bedrooms',y='price',data=df)
sns.scatterplot(x='price',y='long',data=df)
sns.boxplot(x='waterfront',y='price',data=df)


non_top_1_perc = df.sort_values('price',ascending=False).iloc[216:]
sns.scatterplot(x='long',y='lat',
                data=non_top_1_perc,hue='price',
                palette='RdYlGn',edgecolor=None,alpha=0.2)


df['month'] = df['date'].apply(lambda date:date.month)
df.groupby('month').mean()['price'].plot()


from sklearn.metrics import mean_absolute_error,explained_variance_score
explained_variance_score(y_test,predictions)


# Our predictions
plt.scatter(y_test,predictions)
# Perfect predictions
plt.plot(y_test,y_test,'r')


from tensorflow.keras.callbacks import EarlyStopping
early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)

model.fit(x=X_train, 
          y=y_train, 
          epochs=600,
          validation_data=(X_test, y_test), verbose=1,
          callbacks=[early_stop]
          )


## make prediction 
predictions = model.predict_classes(X_test)
print(classification_report(y_test,predictions))


model_loss = pd.DataFrame(model.history.history)
model_loss.plot()


### 
sns.countplot(x='loan_status',data=df)
## histogram 
sns.distplot(df['loan_amnt'],kde=False,bins=40)
## heatmap
sns.heatmap(df.corr(),annot=True,cmap='viridis')
plt.ylim(10, 0)